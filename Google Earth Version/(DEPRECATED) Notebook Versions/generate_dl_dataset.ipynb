{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2503ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant Classes \n",
    "import numpy as np\n",
    "import math\n",
    "import pickle as pkl\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "sys.path.append(\"../\")\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from gzip import compress, decompress\n",
    "sys.path.append(\"../UI_Labeling\")\n",
    "from tqdm.notebook import tqdm\n",
    "import ee\n",
    "ee.Initialize()\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "import PIL\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc73ad",
   "metadata": {},
   "source": [
    "## Editable Variables, change as needed\n",
    "## Ensure the ../UI_Labeling/config.py file has the correct user information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be55f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName='googletest_state_sampled_slender_panda'\n",
    "pathway='../UI_Labeling/Temp Images/'+datasetName\n",
    "PATHNAME='Image_Datasets/googletest_state_sampled_bangladesh_dl_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9948ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CSV_from_dict_keys(confirmed,denied,lrimage,start):\n",
    "    columns=[]\n",
    "    count=start\n",
    "    \n",
    "    #Iterate through our image dictionary and save the image array according to the respective classification\n",
    "    print(\"Downloading Images to \"+ PATHNAME +\" folders!\")\n",
    "    for key in tqdm(lrimage.keys()):\n",
    "        folder=''\n",
    "        if key in confirmed:\n",
    "            label=1\n",
    "            folder='positives/'\n",
    "        elif key in denied:\n",
    "            label=0\n",
    "            folder='negatives/'\n",
    "        else:\n",
    "            continue;\n",
    "        columns.append([folder+str(count)+'.npy',label,lrimage[key][1],key])\n",
    "        np.save(PATHNAME+folder+str(count),lrimage[key][0])\n",
    "        count+=1\n",
    "        \n",
    "    #Check for existing metadata file and either add to or create using the collected column information    \n",
    "    if os.path.exists(PATHNAME+'metadata.csv'):\n",
    "        print(\"Adding to metadata.csv in \"+PATHNAME+\"!\")\n",
    "        with open(PATHNAME+'metadata.csv','a',newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(columns)\n",
    "    else:\n",
    "        print(\"Writing to metadata.csv in \"+PATHNAME+\"!\")\n",
    "        columns.insert(0,['Image','Label','Geometry','Key'])\n",
    "        with open(PATHNAME+'metadata.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb4d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3_band_images(total_dt,batched):\n",
    "    #Create relevant folders\n",
    "    keyImageDict={}\n",
    "    if not os.path.exists(PATHNAME):\n",
    "        os.mkdir(PATHNAME)\n",
    "    if not os.path.exists(PATHNAME+'/positives'):\n",
    "        os.mkdir(PATHNAME+'/positives')\n",
    "    if not os.path.exists(PATHNAME+'/negatives'):\n",
    "        os.mkdir(PATHNAME+'/negatives')\n",
    "    \n",
    "    def loadImage(image):\n",
    "        img=image[0][0]\n",
    "        geom=image[0][1]\n",
    "        key=image[1]\n",
    "        \n",
    "        #Upsample and return img\n",
    "        sr=cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "        path=\"../development/ESPCN_x4.pb\"\n",
    "        sr.readModel(path)\n",
    "        sr.setModel('espcn',4)\n",
    "        result=sr.upsample(img)\n",
    "        keyImageDict[key]=(result,geom)\n",
    "                \n",
    "    #Chunk out the images to pass to getimage to save as we go            \n",
    "    print('Getting Images!')\n",
    "    steps=math.ceil(len(total_dt)/DATASIZE)\n",
    "    for x in range(STARTFROM,steps):\n",
    "        keyImageDict.clear()\n",
    "        \n",
    "        start=x*DATASIZE\n",
    "        if (x != steps-1):\n",
    "            end=(x+1)*DATASIZE\n",
    "        else:\n",
    "            end=(len(total_dt))\n",
    "        batchedImages=[(batched[key],key) for key in total_dt[start:end]]\n",
    "        #Use threadpooling to run through each image\n",
    "        print('Group#',x, 'of',steps-1)\n",
    "        with tqdm(total=len(total_dt[start:end])) as pbar:\n",
    "            with ThreadPool(processes=64) as pool:\n",
    "                for _ in pool.imap_unordered(loadImage,batchedImages):\n",
    "                    pbar.update()\n",
    "        \n",
    "        #Pass the finished key-image dict to our saving function\n",
    "        print('Saving this batch')\n",
    "        create_CSV_from_dict_keys(confirmed,denied,keyImageDict,start)\n",
    "    print('Done!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be09170",
   "metadata": {},
   "source": [
    "## FOR STANDARD DATASET GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58342313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\"\"\"    \n",
    "confirmedFile=open(pathway+'/'+datasetName+'Confirmed','r+b')\n",
    "confirmed=pkl.load(confirmedFile)\n",
    "confirmedFile.close()\n",
    "\n",
    "deniedFile=open(pathway+'/'+datasetName+'Denied','r+b')    \n",
    "denied=pkl.load(deniedFile)\n",
    "deniedFile.close()\n",
    "\n",
    "batched={}\n",
    "prefixed = [filename for filename in os.listdir(pathway+'/') if filename.startswith(datasetName+'LrBatch')]\n",
    "for file in prefixed:\n",
    "    batchFile=open(pathway+'/'+file,'r+b')\n",
    "    batch=pkl.load(batchFile)\n",
    "    batched.update(batch)\n",
    "    batchFile.close()\n",
    "    \n",
    "total_dt={}\n",
    "total_dt.update(denied)\n",
    "total_dt.update(confirmed)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed925ae",
   "metadata": {},
   "source": [
    "## FOR FULL COUNTRY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4afa915b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\ntotalDataset=pd.read_csv('../Predicted_Datasets/'+datasetName+'.csv').to_dict()\\nconfirmed=[]\\ndenied=[]\\nfor idx,key in enumerate(totalDataset['tile_key'].values()):\\n    if totalDataset['prediction'][idx]:\\n        confirmed.append(key)\\n    else:\\n        denied.append(key)\\ntotal_dt=confirmed.extend(denied)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "totalDataset=pd.read_csv('../Predicted_Datasets/'+datasetName+'.csv').to_dict()\n",
    "confirmed=[]\n",
    "denied=[]\n",
    "for idx,key in enumerate(totalDataset['tile_key'].values()):\n",
    "    if totalDataset['prediction'][idx]:\n",
    "        confirmed.append(key)\n",
    "    else:\n",
    "        denied.append(key)\n",
    "total_dt=confirmed.extend(denied)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25d76a27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n",
      "744\n",
      "1218\n"
     ]
    }
   ],
   "source": [
    "print(len(confirmed))\n",
    "print(len(denied))\n",
    "print(len(total_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956747f7",
   "metadata": {},
   "source": [
    "## GET THEM IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec54cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Images!\n",
      "Group# 0 of 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1178cd27b374f5e928126564b6b5270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving this batch\n",
      "Downloading Images to Image_Datasets/googletest_state_sampled_bangladesh_dl_dataset/ folders!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace831b45a504250975bf8145eddeb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to metadata.csv in Image_Datasets/googletest_state_sampled_bangladesh_dl_dataset/!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "get_3_band_images(list(total_dt),batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b683e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c58abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
