{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae50d382-5fde-4e8d-950d-8f8c67366f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "sys.path.append(\"../Configs\")\n",
    "import constants\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d1c787-62b4-44eb-8dd0-f8493b26d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "#model_name = \"FULL_TEST\"\n",
    "#model_name = 'Upsampled_Train_bipn'\n",
    "model_name = 'Hybrid_DL_GEE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5a41cf-1076-4e8d-8f59-58b1da4a3f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class Combo_BI_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for country/ies DL Sentinel2 10-channel imagery.\n",
    "    \"\"\"\n",
    "    def __init__(self, DS_Name, balance=False, limit=0, mode=\"full\",transform=None):\n",
    "        super(Combo_BI_Dataset, self).__init__()\n",
    "        self.df=pd.DataFrame()\n",
    "        self.upsampled=True\n",
    "        self.transform=transform\n",
    "        \n",
    "        def add_dataset(dataset_name):\n",
    "            df=pd.read_csv(constants.IMAGE_DATASETS_ROOT+dataset_name+'/metadata.csv')\n",
    "            if dataset_name == 'bangladesh_dl_dataset' or dataset_name == 'india_dl_dataset':\n",
    "                self.upsampled=False\n",
    "                \n",
    "            if balance:\n",
    "                confirmed={'Image':{},'Label':{},'Geometry':{}}\n",
    "                denied={'Image':{},'Label':{},'Geometry':{}}\n",
    "                for idx in df['Label'].keys():\n",
    "                    if df['Label'][idx]:\n",
    "                        confirmed['Image'][idx]=df['Image'][idx]\n",
    "                        confirmed['Label'][idx]=df['Label'][idx]\n",
    "                        confirmed['Geometry'][idx]=df['Geometry'][idx]\n",
    "                    else:\n",
    "                        denied['Image'][idx]=df['Image'][idx]\n",
    "                        denied['Label'][idx]=df['Label'][idx]\n",
    "                        denied['Geometry'][idx]=df['Geometry'][idx]\n",
    "                        \n",
    "                if limit:\n",
    "                    random.seed(constants.RANDOM_STATE)\n",
    "                    sample_keys=random.sample(list(confirmed['Image'].keys()),min([len(confirmed['Image']),limit]))\n",
    "                    print('Positive size:',len(sample_keys))\n",
    "                    confirmed={'Image':{},'Label':{},'Geometry':{}}\n",
    "                    for idx in sample_keys:\n",
    "                        confirmed['Image'][idx]=df['Image'][idx]\n",
    "                        confirmed['Label'][idx]=df['Label'][idx]\n",
    "                        confirmed['Geometry'][idx]=df['Geometry'][idx]\n",
    "                random.seed(constants.RANDOM_STATE)\n",
    "                sample_keys=random.sample(list(denied['Image'].keys()),min([len(denied['Image']),math.ceil((len(confirmed['Image'])*3))]))\n",
    "                print('Negative Size:',len(sample_keys))\n",
    "                denied={'Image':{},'Label':{},'Geometry':{}}\n",
    "                for idx in sample_keys:\n",
    "                    denied['Image'][idx]=df['Image'][idx]\n",
    "                    denied['Label'][idx]=df['Label'][idx]\n",
    "                    denied['Geometry'][idx]=df['Geometry'][idx]\n",
    "                confirmed['Image'].update(denied['Image'])\n",
    "                confirmed['Label'].update(denied['Label'])\n",
    "                confirmed['Geometry'].update(denied['Geometry'])\n",
    "                df=pd.DataFrame().from_dict(confirmed)\n",
    "            #\"\"\"\n",
    "            df[\"Image\"]=constants.IMAGE_DATASETS_ROOT+dataset_name+'/'+df[\"Image\"]\n",
    "            df=df[['Image','Label']]\n",
    "            return df\n",
    "            \n",
    "    # ADD DATASETS HERE FOR TRAINING\n",
    "        \n",
    "        self.df = pd.concat([self.df,add_dataset(DS_Name)])\n",
    "        \n",
    "    # END EDITABLES\n",
    "        \n",
    "        self.df = self.df.sample(frac=1, random_state=constants.RANDOM_STATE)\n",
    "        \n",
    "        if mode == \"tiny\":\n",
    "            self.df = self.df.sample(frac=.05, random_state=constants.RANDOM_STATE)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name, label = self.df.iloc[idx]\n",
    "        if not self.upsampled:\n",
    "            img = np.load(file_name)[1:4]\n",
    "            sr=cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "            path=\"../ESPCN_x4.pb\"\n",
    "            sr.readModel(path)\n",
    "            sr.setModel('espcn',4)\n",
    "            rgb=np.transpose(img)\n",
    "            rgb=rgb-np.min(rgb)\n",
    "            rgb=rgb/np.max(rgb)\n",
    "            rgb = np.uint8(255 * rgb)\n",
    "            result=sr.upsample(rgb)\n",
    "            img = torch.Tensor(result/256).to(device)\n",
    "        else:\n",
    "            img = torch.Tensor(np.load(file_name)/256).to(device)\n",
    "        \n",
    "        if self.transform:\n",
    "            img=self.transform(img)\n",
    "            img=img*256\n",
    "        else:\n",
    "            img=img*256\n",
    "        img.int()\n",
    "            \n",
    "        label = torch.Tensor([label]).to(device)\n",
    "        \n",
    "        return img, label\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb62475-33df-4690-ac0a-2af9e046d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "class Resnet(torch.nn.Module):\n",
    "    def __init__(self, num_channels, image_width=64, device=None, pretrained=False):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.device = device        \n",
    "        self.resnet = resnet18(pretrained=pretrained)\n",
    "        self.resnet.conv1 = torch.nn.Conv2d(num_channels, image_width, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, 256).to(device)\n",
    "        self.final_fc = torch.nn.Linear(256, 1).to(device)\n",
    "        \n",
    "        self.resnet = self.resnet.to(device)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        resnet_output = self.resnet(x)\n",
    "        outputs = self.final_fc(resnet_output)\n",
    "        outputs = self.sigmoid(outputs)\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c5bea4-7515-4d8d-8e3f-22ffa5c7ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model_checkpoint, model, device, optimizer=None):\n",
    "    \"\"\"\n",
    "    Loads a pretrained checkpoint to continue training\n",
    "    model_checkpoint: Path of the model_checkpoint that ends with .pth\n",
    "    model: model to load to\n",
    "    device: devide to load on (gpu/cpu)\n",
    "    optimizer (optional): optimize to load state to\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(model_checkpoint, map_location=device)\n",
    "    print('Loaded best state dict from epoch: {}'.format(checkpoint[\"epoch\"]))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        all_outputs = []\n",
    "        for batch_iter, (inputs, labels) in enumerate(val_loader):\n",
    "            outputs = model(np.transpose(inputs.cpu(),(0,3,1,2)).to(device)).to(device)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            outputs = outputs.cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            preds = (outputs > .5).astype('int')\n",
    "            \n",
    "            all_labels.append(labels)\n",
    "            all_preds.append(preds)\n",
    "            all_outputs.append(outputs)\n",
    "        \n",
    "        all_labels = np.array([label for vec in all_labels for label in vec])\n",
    "        all_preds = np.stack([pred for vec in all_preds for pred in vec])\n",
    "        all_outputs = np.stack([output for vec in all_outputs for output in vec])\n",
    "        val_acc = np.mean((all_labels == all_preds).astype('int'))\n",
    "            \n",
    "    return val_acc, running_loss / batch_iter, all_labels, all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5024593-2ea8-4a1c-bde8-76a75af47ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive size: 500\n",
      "Negative Size: 719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor dset in dataset:\\n    if val_dset is None:\\n        val_dset=dset\\n    else:\\n        val_dset=torch.utils.data.ConcatDataset([val_dset,dset])\\nprint(f\"{len(val_dset)} validation examples.\")\\nval_loader = DataLoader(val_dset, batch_size=64,shuffle=True)\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=[]\n",
    "val_dset=None\n",
    "transformList=None\n",
    "#\"\"\"\n",
    "#Commend or uncomment for datasets you'd like to add.\n",
    "#dataset.append(Combo_BI_Dataset('bangladesh_dl_dataset',True,858,transform=transformList))\n",
    "#dataset.append(Combo_BI_Dataset('Upsampled0_high_sampled_india_dl_dataset',True,858,transform=transformList))\n",
    "#dataset.append(Combo_BI_Dataset('Upsampled0_updatedModel_state_sampled_pakistan_dl_dataset',True,858,transform=transformList))\n",
    "#dataset.append(Combo_BI_Dataset('Upsampled0_updatedModel_state_sampled_nepal_dl_dataset',True,858,transform=transformList))\n",
    "#\"\"\"\n",
    "#\"\"\"\n",
    "#Commend or uncomment for datasets you'd like to add.\n",
    "dataset.append(Combo_BI_Dataset('FULL_TEST_calm_panda',True,858,transform=transformList))\n",
    "#dataset.append(Combo_BI_Dataset('FULL_TEST_calm_snake',True,858,transform=transformList))\n",
    "#dataset.append(Combo_BI_Dataset('FULL_TEST_fiery_pig',True,858,transform=transformList))\n",
    "#dataset.append(Combo_BI_Dataset('FULL_TEST_gaudy_snake',True,858,transform=transformList))\n",
    "#\"\"\"\n",
    "\"\"\"\n",
    "for dset in dataset:\n",
    "    if val_dset is None:\n",
    "        val_dset=dset\n",
    "    else:\n",
    "        val_dset=torch.utils.data.ConcatDataset([val_dset,dset])\n",
    "print(f\"{len(val_dset)} validation examples.\")\n",
    "val_loader = DataLoader(val_dset, batch_size=64,shuffle=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6290ac33-6d60-464d-9207-ac00d3bf1a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "975 training examples and 244 validation examples.\n"
     ]
    }
   ],
   "source": [
    "train_dset=[]\n",
    "val_dset=[]\n",
    "for dset in dataset:\n",
    "    train, val = torch.utils.data.random_split(\n",
    "        dset, \n",
    "        [len(dset)*8//10, len(dset)-len(dset)*8//10], # 80-20% split\n",
    "        generator=torch.Generator().manual_seed(0)\n",
    "    )\n",
    "    buff=[val[x] for x in range(len(val)) if val[x][1][0]==1. ]\n",
    "    print(len(buff))\n",
    "    if train_dset is None and val_dset is None:\n",
    "        train_dset=train\n",
    "        val_dset=val\n",
    "    else:\n",
    "        train_dset=torch.utils.data.ConcatDataset([train_dset,train])\n",
    "        val_dset=torch.utils.data.ConcatDataset([val_dset,val])\n",
    "print(f\"{len(train_dset)} training examples and {len(val_dset)} validation examples.\")\n",
    "train_loader = DataLoader(train_dset, batch_size=64,shuffle=True)\n",
    "val_loader = DataLoader(val_dset, batch_size=64,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "782d522f-ab1b-4686-88e2-d7dfa38f3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's give it a whirl\n",
    "\n",
    "# some things to try for speedups:\n",
    "# torch.cuda.empty_cache()\n",
    "# change number of workers, use detach instead of just \n",
    "N_EPOCHS = 50\n",
    "model = Resnet(3, device=device)\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "best_val_loss = None\n",
    "\n",
    "logdir = constants.MODEL_ROOT+model_name+\"_50_training_steps/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83496262-850d-4997-a594-cedd3e8e49d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best state dict from epoch: 6\n",
      "Loaded best state dict from epoch: 19\n"
     ]
    }
   ],
   "source": [
    "#let's test this bad boy\n",
    "best_val_model = Resnet(3, device=device)\n",
    "final_epoch_model = Resnet(3, device=device)\n",
    "\n",
    "best_val_model = load_checkpoint(f\"{logdir}/checkpoints/best_dl_best.pth\", \n",
    "                                 best_val_model, \n",
    "                                 device)\n",
    "#best_val_model = load_checkpoint('kiln_prod_weights.pth',best_val_model,device)\n",
    "final_epoch_model = load_checkpoint(f\"{logdir}/checkpoints/last_dl_last.pth\", \n",
    "                                    final_epoch_model, \n",
    "                                    device)\n",
    "\n",
    "#final_epoch_model = load_checkpoint(f\"{logdir}/checkpoints/lr0.0001_epoch49.pth\", \n",
    "#                                    final_epoch_model, \n",
    "#                                    device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52291a06-76d0-4369-972a-0d8a1b32051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc, best_val_loss, best_labels, best_outputs = evaluate_model(best_val_model, \n",
    "                                                                        val_loader)\n",
    "final_val_acc, final_val_loss, final_labels, final_outputs = evaluate_model(final_epoch_model, \n",
    "                                                                            val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bc6e348-6c0e-4745-b92b-fabf9a58a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.9877049180327869 0.075228667507569\n",
      "Last: 0.9549180327868853 0.24655809998512268\n"
     ]
    }
   ],
   "source": [
    "print('Best:',best_val_acc, best_val_loss)\n",
    "print('Last:',final_val_acc, final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402164ab-9f95-4d79-9780-5e101c0bf5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
