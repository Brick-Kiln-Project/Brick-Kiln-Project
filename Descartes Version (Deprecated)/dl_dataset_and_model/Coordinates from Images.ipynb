{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07a56ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/descarteslabs/_dl_modules/common/workflows/arrow_serialization/context.py:57: FutureWarning: 'pyarrow.SerializationContext' is deprecated and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  serialization_context = pa.SerializationContext()\n",
      "/opt/conda/lib/python3.7/site-packages/descarteslabs/_dl_modules/common/workflows/arrow_serialization/context.py:58: FutureWarning: 'pyarrow.register_default_serialization_handlers' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  pa.register_default_serialization_handlers(serialization_context)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.7/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-contrib-python) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "# try the imports\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../\")\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append('../UI_Labeling')\n",
    "from random import sample\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import cv2\n",
    "import json\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import Point\n",
    "import geopandas\n",
    "from descarteslabs.scenes import DLTile\n",
    "import geojson\n",
    "import descarteslabs.workflows as wf\n",
    "from ipyleaflet import GeoJSON\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import descarteslabs as dl\n",
    "\n",
    "!{sys.executable} -m pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ff9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "upsampled_model_name = \"Upsampled_bipn\"\n",
    "upsampledlogdir = \"model_log_dl/\"+upsampled_model_name+\"_50_training_steps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4616c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampledResnet(torch.nn.Module):\n",
    "    def __init__(self, num_channels, image_width, device=None, pretrained=False):\n",
    "        super(UpsampledResnet, self).__init__()\n",
    "        self.device = device        \n",
    "        self.resnet = resnet18(pretrained=pretrained)\n",
    "        self.resnet.conv1 = torch.nn.Conv2d(num_channels, image_width, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.upsample = torch.nn.Upsample(scale_factor=8)\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, 256).to(device)\n",
    "        self.final_fc = torch.nn.Linear(256, 1).to(device)\n",
    "        \n",
    "        self.resnet = self.resnet.to(device)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.upsample(x)\n",
    "        resnet_output = self.resnet(x)\n",
    "        outputs = self.final_fc(resnet_output)\n",
    "        outputs = self.sigmoid(outputs)\n",
    "        return outputs\n",
    "    \n",
    "def load_checkpoint(model_checkpoint, model, device, optimizer=None):\n",
    "    \"\"\"\n",
    "    Loads a pretrained checkpoint to continue training\n",
    "    model_checkpoint: Path of the model_checkpoint that ends with .pth\n",
    "    model: model to load to\n",
    "    device: devide to load on (gpu/cpu)\n",
    "    optimizer (optional): optimize to load state to\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(model_checkpoint, map_location=device)\n",
    "    print('Loaded best state dict from epoch: {}'.format(checkpoint[\"epoch\"]))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34196e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCAM(feature_conv, weight_softmax, class_idx, kernel, size_upsample):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    labeled=[]\n",
    "    nr_objects=[]\n",
    "    centers=[]\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = np.transpose(cam)\n",
    "        #normalize\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        \n",
    "        #calculate mean and convolute using large mask\n",
    "        #\"\"\"\n",
    "        mean = np.mean(cam[np.nonzero(cam)])\n",
    "        cam = cam-mean\n",
    "        cam = np.clip(cam,0,None)\n",
    "        #convolve=signal.convolve2d(cam,np.ones((9,9))/81)\n",
    "        #cam=convolve\n",
    "        cam = cv2.GaussianBlur(cam,(kernel,kernel),0)\n",
    "        \n",
    "        \n",
    "        #calculate mean and convolute using medium mask\n",
    "        #\"\"\"\n",
    "        mean = np.mean(cam[np.nonzero(cam)])\n",
    "        cam = cam-mean\n",
    "        cam = np.clip(cam,0,None)\n",
    "        \n",
    "        cam = cv2.GaussianBlur(cam,(kernel,kernel),0)\n",
    "        #\"\"\"\n",
    "        \n",
    "        #calculate mean and convolute using small mask\n",
    "        #\"\"\"\n",
    "        mean = np.mean(cam[np.nonzero(cam)])\n",
    "        cam = cam-mean\n",
    "        cam = np.clip(cam,0,None)\n",
    "        #\"\"\"\n",
    "        \n",
    "        #calculate mean and send the final cam\n",
    "        #\"\"\"\n",
    "        mean = np.mean(cam[np.nonzero(cam)])\n",
    "        cam = cam-mean\n",
    "\n",
    "        #cam = np.clip(cam,0,None)\n",
    "        #mean = np.mean(cam[np.nonzero(cam)])\n",
    "        #cam = cam-mean\n",
    "        #\"\"\"\n",
    "        cam=cv2.resize(cam, (size_upsample,size_upsample))\n",
    "        cam_img = np.clip(cam,0,None)\n",
    "        cam_img = cam_img-(np.max(cam)*.75)\n",
    "        cam_img=np.clip(cam,0,None)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cam_img)\n",
    "        labeled1,nr_objects1=ndimage.label(output_cam)\n",
    "        labeled.append(labeled1)\n",
    "        nr_objects.append(nr_objects1)\n",
    "        centers1=ndimage.measurements.center_of_mass(output_cam[-1].squeeze(),labeled[-1].squeeze(),range(1,nr_objects1+1))\n",
    "        centers.append(centers1)\n",
    "    return output_cam,labeled,nr_objects,centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2c00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnOriginalCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam=np.transpose(cam)\n",
    "        \n",
    "        #normalize\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        \n",
    "        cam_img = np.clip(cam,0,None)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cam_img)\n",
    "        \n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e2c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName='Image_Datasets/all_2021_bangladesh_dl_dataset/'\n",
    "df = pd.read_csv(datasetName+\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac4f988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best state dict from epoch: 10\n"
     ]
    }
   ],
   "source": [
    "upsamplednet = UpsampledResnet(3,64, device=device)\n",
    "upsamplednet = load_checkpoint(f\"{upsampledlogdir}/checkpoints/best_dl_best.pth\", \n",
    "                                 upsamplednet, \n",
    "                                 device)\n",
    "upsamplednet.to(device)\n",
    "upsampled_conv_name='layer4'\n",
    "upsamplednet.eval()\n",
    "\n",
    "upsampled_features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    upsampled_features_blobs.append(output.data.cpu().numpy())\n",
    "upsamplednet._modules.get('resnet')._modules.get(upsampled_conv_name).register_forward_hook(hook_feature)\n",
    "\n",
    "upsampledparams = list(upsamplednet.parameters())\n",
    "upsampled_weight_softmax = [np.dot(np.squeeze(upsampledparams[-2].data.numpy()),(np.squeeze(upsampledparams[-4].data.numpy())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71452c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e381b6d6b83946c5b0c2ee1421e4d640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m=wf.interactive.MapApp()\n",
    "m.center=(25,89)\n",
    "m.zoom=8\n",
    "#for batch in tqdm(range(1,math.ceil(len(df['Geometry'])/500))):\n",
    "    #short = df['Geometry'][batch*500:(batch+1)*500]\n",
    "with tqdm(total=len(df['Geometry'])) as pbar:\n",
    "    latlons={}\n",
    "    for idx,x in enumerate(df['Geometry']):\n",
    "        if df['Label'][idx]:\n",
    "            image=df['Image'][idx]\n",
    "            tile=dl.scenes.DLTile.from_key(df['Key'][idx])\n",
    "            upsampledimg=np.load(datasetName+image)\n",
    "            upsampledimg = np.transpose(upsampledimg,(2,0,1))\n",
    "            upsampledimg=torch.Tensor(upsampledimg).to(device)\n",
    "            upsampledlogit=upsamplednet(Variable(upsampledimg.unsqueeze(0)))\n",
    "            upsampledh_x=F.softmax(upsampledlogit,dim=1).data.squeeze()\n",
    "            upsampledprobs,upsampledidx=upsampledh_x.sort(0,True)\n",
    "            upsampledprobs=upsampledprobs.numpy()\n",
    "            upsampledidx=upsampledidx.numpy()\n",
    "            upsampledCAMs,upsampledlabeled,upsamplednr_objects,upsampledcenters=returnCAM(upsampled_features_blobs[-1],[upsampled_weight_softmax[-1]*-1],[upsampledidx],9,upsampledimg.shape[1])\n",
    "            upsampledoCAMs = returnOriginalCAM(upsampled_features_blobs[-1],[upsampled_weight_softmax[-1]*-1],[upsampledidx])\n",
    "            temp=[]\n",
    "            for centers in upsampledcenters[0]:\n",
    "                coord=tile.rowcol_to_latlon(round(centers[0]/4),round(centers[1]/4))\n",
    "                temp.append((coord[0][0],coord[1][0]))\n",
    "\n",
    "                #Place point markers on the map\n",
    "                \"\"\"\n",
    "                subtilegjs=GeoJSON(\n",
    "                    data=geojson.FeatureCollection([geopandas.GeoSeries(Point((coord[1][0],coord[0][0]))).__geo_interface__]),\n",
    "                    style={\"color\":'green',\n",
    "                          \"fillOpacity\":0,\n",
    "                          \"weight\":5}\n",
    "                )\n",
    "                m.add_layer(subtilegjs)\n",
    "                #\"\"\"\n",
    "            latlons[df['Key'][idx]]=temp\n",
    "            upsampled_features_blobs=[]\n",
    "            #Place squares on predicted tiles on map\n",
    "            \"\"\"\n",
    "            temp=geopandas.GeoSeries(loads(x)).__geo_interface__\n",
    "            subtilegjs=GeoJSON(\n",
    "                data=geojson.FeatureCollection([temp]),\n",
    "                style={\"color\":\"red\",\n",
    "                      \"fillOpacity\":0,\n",
    "                      \"weight\":2}\n",
    "            )\n",
    "            m.add_layer(subtilegjs)\n",
    "            #\"\"\"\n",
    "\n",
    "            #Display the tile image and the CAM representations\n",
    "            \"\"\"\n",
    "            fig=plt.figure()\n",
    "            fig.suptitle('Upsampled Model')\n",
    "            fig.add_subplot(2,2,2)\n",
    "            plt.imshow(upsampledoCAMs[-1])\n",
    "            plt.title('Original CAM')\n",
    "            fig.add_subplot(2,2,3)\n",
    "            plt.imshow(upsampledCAMs[-1])\n",
    "            plt.title('Filtered CAM')\n",
    "            fig.add_subplot(2,2,4)\n",
    "            plt.imshow(np.transpose(upsampledlabeled[-1],(1,2,0)))\n",
    "            plt.title('Group CAM')\n",
    "            fig.add_subplot(2,2,1)\n",
    "            plt.imshow(np.transpose(upsampledimg.int(),(2,1,0)))\n",
    "            plt.title('Original Img')\n",
    "            #\"\"\"\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "    with open (r'2021Bangladesh_KilnCoords.json','w') as outfile:\n",
    "        json.dump(latlons,outfile)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8135ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324fd9951d864a17b15783975738e4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
